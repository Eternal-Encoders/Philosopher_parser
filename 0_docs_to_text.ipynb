{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d91bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import base64\n",
    "import torch\n",
    "from markitdown import MarkItDown\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06726f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e324cca430040b0a1eb5cedee7295d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "m_path = 'Qwen/Qwen2.5-VL-3B-Instruct'\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    m_path,\n",
    "    dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    m_path,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "model = torch.compile(\n",
    "    model,\n",
    "    mode='max-autotune',\n",
    "    fullgraph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MarkItDown()\n",
    "result = md.convert(\n",
    "    './__input__/Учебник_философии_22_августа_ТюмГУ.docx',\n",
    "    keep_data_uris=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892cc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./__output__/study_fies.md', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac62252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uri(full_match: str) -> str:\n",
    "    uri_mask = r'(!\\[\\]\\(data:image/(png|jpeg);base64,)|(\\))'\n",
    "    return re.sub(uri_mask, '', full_match)\n",
    "\n",
    "\n",
    "def get_image(uri: str) -> Image.Image:\n",
    "    return Image.open(\n",
    "        BytesIO(\n",
    "            base64.b64decode(uri)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f64648",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask = r'!\\[\\]\\(data:image/(png|jpeg);base64,.+\\)'\n",
    "iters = re.finditer(image_mask, result.text_content)\n",
    "\n",
    "visited = set()\n",
    "images = []\n",
    "\n",
    "for i, img_str in enumerate(iters):\n",
    "    img_str = img_str.group()\n",
    "\n",
    "    if img_str not in visited:\n",
    "        uri = get_uri(img_str)\n",
    "        img  = get_image(uri)\n",
    "        img_name = f'image_{i}.png'\n",
    "\n",
    "        images.append((\n",
    "            img_name,\n",
    "            img,\n",
    "            img_str,\n",
    "        ))\n",
    "        visited.add(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd8e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msg(img: Image.Image):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'image',\n",
    "                    'image': img,\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': 'Translate image to text, save core meaning, include all text from image in your responce'\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_input(messages):\n",
    "    texts = [\n",
    "        processor.apply_chat_template(\n",
    "            msg,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        for msg in messages\n",
    "    ]\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "\n",
    "    return processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "\n",
    "def get_images_str(imgs: list[Image.Image], batch_size=4):\n",
    "    res = []\n",
    "    for i in trange(0, len(imgs), batch_size):\n",
    "        batch = imgs[i:i+batch_size]\n",
    "        msgs = [\n",
    "            get_msg(img)\n",
    "            for img in batch\n",
    "        ]\n",
    "        inputs = get_input(msgs)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256\n",
    "        )\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :]\n",
    "            for in_ids, out_ids in zip(\n",
    "                inputs.input_ids,\n",
    "                generated_ids\n",
    "            )\n",
    "        ]\n",
    "        res.extend((\n",
    "            t.replace('\\n', '. ')\n",
    "            for t in processor.batch_decode(\n",
    "                generated_ids_trimmed,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=False\n",
    "            )\n",
    "        ))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02276c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb6a3b8017a442cb1f3b9bf89bd4656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "d:\\GitProjects\\Philosopher_parser\\.venv\\Lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ДНК РОССИИ БИБЛИОТЕКА ПРОЕКТА',\n",
       " 'The image depicts a document with checkmarks and a gear icon. The document appears to be a checklist or a list of items, indicated by the checkmarks. The gear icon suggests that this is related to settings or configuration, possibly indicating a process for managing or adjusting settings based on the checklist.',\n",
       " 'The image depicts a document with checkmarks and a gear icon. The document appears to be a checklist or a list of items, indicated by the checkmarks. The gear icon suggests that this is related to settings or configuration, possibly indicating a process for managing or adjusting settings based on the checklist.',\n",
       " 'И',\n",
       " 'Новое знание. . Индивидуальное. . Сознание. Личность. I Человек. Тело. Свобода. . Сохранение. . Вера (Надежда). . Размножение. . Коллективное. . Методы научного познания. АСТ. Герменевтика. Феноменология. Диалектика. . Методология. Логика. Аргументация. . IV Язык. . IX История. Современность. Цивилизация. . VIII Природа. Культура. Пространство. . IX Мировоззрение. Картина мира. Ценности. . XI.Бытие. Бессмертность. . XII Русская идея как эпистема. . VI Знание. Эпистемология. . VII Познание. Мудрость. Соборность. . IX Деятельность. Потребность. Мотив. . III Деятельность. Потребность. Мотив. . II Этика. Мораль. Добро. . IX И',\n",
       " '. . . ',\n",
       " '',\n",
       " '',\n",
       " 'КОНФИГУРАЦИИ. . ТРЕБОВАНИЯ. ФУНКЦИОНАЛЬНАЯ. ТЕХНИЧЕСКИЙ. . КОМПОНЕНТЫ. ТИП. АТРИБУТЫ',\n",
       " 'ПРОШЛОЕ. Надсистема. БУДУЩЕЕ. . СИСТЕМА. Подсистема. БУДУЩЕЕ. . ПРОШЛОЕ. ПРОШЛОЕ. БУДУЩЕЕ',\n",
       " 'СХЕМА КРИТИЧЕСКОГО МЫШЛЕНИЯ. . КРИТИЧЕСКОЕ МЫШЛЕНИЕ. . АНАЛИЗ. - Оценивает компетентность источника. - Оценивает релевантность информации. . СИНТЕЗ. - Разрабатывает валидные выводы. - Определяет последствия вывода. . УПРАВЛЕНИЕ ПРИЧИННО-СЛЕДСТВЕННЫМИ СВЯЗЯМИ. - Создает объяснения. - Оценивает причинно-следственные связи. . РАМКА ИНСТРУМЕНТА',\n",
       " 'О',\n",
       " 'Б',\n",
       " 'СХЕМА «ШАГ РАЗВИТИЯ». . «Прошлое». →. проблема. . анализ ситуации. . «Будущее». →. изменение в ситуации, преодолевающее затруднение. образ будущего',\n",
       " 'M']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    img\n",
    "    for _, img, _ in images\n",
    "]\n",
    "translations = get_images_str(data, batch_size=3)\n",
    "\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e76154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = result.text_content\n",
    "for (file_name, _, orig_str), text in zip(images, translations):\n",
    "    new_str = f'![{text}](media/{file_name})'\n",
    "    txt = txt.replace(orig_str, new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72df647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./__output__/study_fies_no_uri.md', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab810878",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, img,_ in images:\n",
    "    img.save(f'./__output__/media/{file_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
